In line with our philosophy of custom building a solution most efficient for each query, we present different system architectures to handle Query 1 and Query 2. In case of Query 1, we need to forecast the average load of each house as well as of each plug. The predicted load depends only on the values inside the house. Whereas, in case of Query 2, we need to find percentage of plugs having their median load within a house larger than the global median, every time we receive a new event. The global median is computed using all the data of all the plugs in the system and then compared with median of each plug. The requirements of each of these queries dictated the following design choices:

\begin{enumerate}
\item Since the load prediction even for a house is dependent only on median values within the house, it is possible to process data for different houses in parallel (possibly on different nodes) in case of Query 1. On the other hand, a distributed system in case of Query 2, will require a large number of messages among the processes to compute the global median before outputting an event. Hence we choose to design the system so that it is distributed by house for query 1 while it is a single process for query 2. 
\item Query 2 computes the median for a large set of data - potentially  of $(24 \mbox{hrs} * 3600 \mbox{sec} * 2125 \mbox{plugs}) \approx 270 \ \mbox{million}$ numbers. Computing the exact median of so many numbers multiple times each second will be computationally intensive. We therefore compute approximate medians in this case. Whereas in Query 1, we compute medians of at most 30 numbers (each data item corresponds to each day in the month). Computing exact median would be feasible in this case.
\end{enumerate}

We have used C++ programming language in order to implement the solution we present in this paper. We have used Arrays and Hashmaps as our primary data structures in order to store data for quick lookups and quick binary searches.  Due to the fact that the number of households in a house and number of plugs in a household are not known apriori, we had to sometimes use hashmaps in place of arrays to store data containers for different plugs, households.
